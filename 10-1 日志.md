### 日志



日志、链路追踪和指标是微服务本身的可观测性的技术手段。



#### 日志级别

[glog](https://github.com/golang/glog)，是google提供的一个不维护的日志库，glog有其他语言的一些版本。它包含如下日志级别：

+ info
+ warning
+ error
+ fatal (会中断程序执行)

还有类似log4go、loggo、zap等其他第三方日志库，它们还提供了设置日志级别的可见性，一般提供日志级别：

+ trace
+ debug
+ info
+ warning
+ error
+ critical



#### warning

从定义上讲，warning表示没有什么出错。也许将来会出问题，但这听起来像是别人的问题。这导致开发习惯性忽略这个告警。

此时要尽可能地消除warning级别，它要么是一条消息(info)的消息，要么是一个错误(error)。



参考Go语言设计的哲学，所有警告都是错误，其他语言的warning都可以忽略，除非IDE或者在CICD流程中强制他们为error，然后迫使程序员尽可能去消除。同样的，如果想要最终消除warning可以记录为error，让代码作者重视起来。

#### fatal

记录消息后，直接调阅`os.Exit(1)`，这意味着：

+ 在其他goroutine defer语句不会被执行
+ 各种buffers不会被刷盘，包括日志的
+ 临时文件或者目录不会被移除

不要使用fatal(调用了`exit`)记录日志，而向调用者返回错误。如果错误一直持续到`main.main`,那么确保`main.main`在退出之前做好一些必要清理操作。

#### error

error的处理应该是往上层抛出错误，或者处理掉这个错误。而不是在错误发生的地方立马记录日志，尤其要使用error级别记录。

如果出现了一个error，要么处理掉它，就不应该再往上层返回error；要么不处理它，或者只是封装一些错误的根因，然后往上层抛出，由程序的最顶层去统一打日志。

```go
if err := planA(); err != nil {
  // log.Error("oops, open error")
  // return err
  log.Warningf("coun't open the foo file, continuing")
  planB()
}
```

上面例子中降级处理了错误，同时使用waring(或info)表明降级产生了有损服务的行为，让程序员重视起来，因为降级不应该常发生，需要重视处理。

**debug**

开发记录日志时应该关注两件事情：

+ 程序员在开发或调试软件时关心的事情
+ 用户在使用软件时关心的事情

显然，它们分别是调试和信息级别。

`log.info`只需将该行写入日志输出。不应该有关闭它的选项，因为用户只应该被告知对他们有用的事情。如果发生了无法处理的错误，它就会抛出到`main.main`，`main.main`是程序终止的地方。在最后的日志消息前面插入`fatal`前缀，或者直接写入`os.Stderr`。



`log.Debug`，是完全不同的事情。它由程序员或支持工程师控制。在开发过程中，调试语句应该是丰富的，而不必求助于`trace`或`debug2`级别。日志包应该支持细粒度控制，以启用或禁用调试，而且只在包或更精细的范围内启用或禁用调试语句。



#### 日志选项



一个完整的集中式日志系统，需要包含以下几个主要特点：

+ 收集 - 能够采集多种来源的日志数据
+ 传输 - 能够稳定地把日志数据传输到中央系统
+ 存储 - 如何存储日志数据
+ 分析 - 可以支持UI分析
+ 警告 - 能够提供错误报告，监控机制

`ELK stack`分别表示`Elesticsearch`、`Logstach`和`Kibana`，它们都是开源软件。新增了一个`FileBeat`，它是一个经量级的日志收集工具(Agent)，`FileBeat`占用资源少，适合于在各个服务器上搜集日志后传输给`Logstash`，官方也推荐此工具。

![image](https://github.com/lecc2cc/microgo/blob/master/images/10-01-2021-06-22-23.png?raw=true)

工作流程：

![image](https://github.com/lecc2cc/microgo/blob/master/images/10-01-logstash-2021-06-22-23.png?raw=true)

此架构由Logstash分布于各个节点上搜集相关日志，数据，并经过分析，过滤后发送给远端服务器上的Elasticsearch进行存储。

Elasticsearch将数据以分片的形式压缩存储并提供多种API供用户查询，操作。用户亦可以更直观地通过配置Kibana Web方便的对日志查询，并根据数据生产报表。

因为Logstash属于server角色，必然出现流量集中式的热点问题，因此不建议使用这种部署方式，同时因为还需要做大量的match操作(格式化日志)，消耗的CPU也很多，不利于scale out。



![image](https://github.com/lecc2cc/microgo/blob/master/images/10-01-mq-2021-06-24-23.png?raw=true)

此种架构引入了消息队列机制，位于各个节点上的 Logstash Agent 先将数据/日志传递给 Kafka，并将队列中消息或数据间接传递给 Logstash，Logstash 过滤、分析后将数据传递给Elasticsearch 存储。最后由 Kibana 将日志和数据呈现给用户。

因为引入了 Kafka，所以即使远端 Logstash server 因故障停止运行，数据将会先被存储下来，从而避免数据丢失。

更进一步的：将收集端 logstash 替换为 beats，更灵活，消耗资源更少，扩展性更强。

#### 设计目标

+ 接入方式收敛(不同语言、不同业务部门是统一的)
+ 日志格式规范
+ 日志解析对日志系统透明
+ 系统高吞吐、低延迟
+ 系统高可用、容量可扩展、高可运维性

#### 规范

JSON作为日志的输出格式：

+ time: 日志产生时间，ISO8601格式
+ level: 日志级别，ERROR、WARN、INFO、DEBUG
+ app_id：应用id，用于标识日志来源
+ instance_id：实例id，用于区分同一应用不同实例，即hostname.

可以使用otel规范（Open Tracing 和 OpenCensus ）。



#### 设计与实现



日志从产生到可检索，经历几个阶段：

+ 生产 & 采集
+ 传输 & 切分
+ 存储 & 检索

**`logstash`**：

- 监听 tcp/udp
- 适用于通过网络上报日志的方式

**`filebeat`**：

- 直接采集本地生成的日志文件
- 适用于日志无法定制化输出的应用

**`logagent`**：

- 物理机部署，监听 unixsocket
- 日志系统提供各种语言 SDK
- 直接读取本地日志文件

![image](https://github.com/lecc2cc/microgo/blob/master/images/10-01-impl-2021-06-24-23.png?raw=true)