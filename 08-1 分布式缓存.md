### 分布式缓存

+ 缓存选型
+ 缓存模式
+ 缓存技巧

#### 缓存选型

**memcache**

memcache 提供简单的kv cache存储，value大小不超过1mb。

memcache 作为大文本或者简单的kv结构使用。 使用了slab(分块)方式做内存管理，存在一定的浪费，如果大量接近的item，建议调整memcache参数来优化每一个slab增长的ratio、可以通过设置slab_automove和slab_reassign开启memcache的动态/手动move slab，防止某些slab热点导致内存足够的情况下引发LRU。

大部分情况下，简单KV推荐使用memcache，吞吐和响应都足够好。



![image](https://github.com/lecc2cc/microgo/blob/master/images/08-mem-2021-06-07-23.png?raw=true)

每个slab包含若干大小为1M的内存页，这些内存又被分割成多个chunk，每个chunk存储一个item；

在memcache启动初始化时，每个slab都预分配一个1M的内存页，由slabs——preallocate完成。chunk的增长因子由-f指定，默认1.25，起始大小为48字节。



**redis**



redis有丰富的数据类型，支持增量方式的修改部分数据，比如排行榜，集合，数组等。

redis因为没有使用内存池，所以是存在一定的内存碎片，一般使用jemalloc来优化内存分配，需要编译时使用jemalloc库替代glib的malloc使用。



redis和memcache最大的区别其实是redis单线程(新版本双线程)、memcache多线程，所以QPS可能两者差异不大，但是吞吐会有很大的差别，比如大数据value返回的时候，redis qps会抖动下降的很厉害。



建议纯kv都走memcache，复杂数据类型使用redis。可以使用memcache+redis双缓存设计。



**Proxy**

+ twemproxy

  单进程单线程模型和redis类似，在处理一些大key的时候可能出现IO瓶颈； 二次开发成本难度高，难以与公司运维平台进行深度集成； 不支持自动伸缩，不支持autorebalance，增删结点需要重启才能生效； 运维不友好，没有控制面板；

+ codis

  只支持redis协议，且需要使用patch版本的redis

+ mcrouter

  只支持memcache协议，C开发，运维集成成本难度高。

可以使用最新版的redis cluster。

不管是自带的cluster、第三方的proxy或自研的proxy，多多少少引入一个集中式访问的问题，此时需要去中心化。需要从集中式访问缓存到Sidecar 访问缓存：

+ LVS 运维难度，容易流量热点，随下游扩容而扩容，连接不均衡等问题。
+ Sidecar 伴生容器随APP容器启动而启动，配置简化。

![image](https://github.com/lecc2cc/microgo/blob/master/images/08-08-2021-06-09-23.png?raw=true)



#### 一致性hash

一致性hash将数据按照特征值映射到一个首尾连接的hash环上，同时也将节点（按照IP地址或机器名hash）映射到这个环上。

对于数据，从数据在环上的位置开始，顺时针找到的第一个节点即为数据的存储节点。

余数分布式算法由于保存键的服务器会发生巨大变化而影响缓存的命中率，但Consistent Hashing中，只有在圆(continuum)上增加服务器的地点逆时针方向的第一台服务器上的键会受到影响，从而避免整体命中率抖动问题。

![image](https://github.com/lecc2cc/microgo/blob/master/images/08-09-2021-06-09-23.png?raw=true)

![image](https://github.com/lecc2cc/microgo/blob/master/images/08-10-2021-06-10-00.png?raw=true)

Hash算法的评价

+ 平衡性（Balance）：尽可能分布到所有的缓冲中去。
+ 单调性（Monotonicity）：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲区加入到系统中，那么哈希的结果应能够保证原有已分配的内容可以被映射到新的缓冲区中去，而不会被映射到旧的缓冲集合中的其他缓冲区。
+ 分散性（Spread）：相同内容被存储到不同缓冲中去，降低了系统存储的效率，需要尽量降低分散性。
+ 负载（Load）：哈希算法应能够尽量降低缓冲的负荷。
+ 平滑性（Smoothness）：缓存服务器的数目平滑改变和缓存对象的平滑改变是一致的。

一致性哈希算法在服务节点太少时，容易因为节点分布不均匀而造成数据倾斜问题。

为了解决数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈秀，每个计算结果位置都放置一个此服务节点，称为虚拟节点。

具体做法可以在服务器ip或主机名的后面增加编号来实现。

![image](https://github.com/lecc2cc/microgo/blob/master/images/08-12-202-06-10-23.png?raw=true)

一致性哈希有很多演进版本，比如有界负载一致性hash。

一致性hash的思想：即按照数据的某一特征（key）来计算哈希值，并将哈希值与系统中的节点建立映射关系,从而将哈希值不同的数据分布到不同的节点上。

按照 hash 方式做数据分片，映射关系非常简单；需要管理的元数据也非常之少，只需要记录节点的数目以及 hash 方式就行了。

当加入或者删除一个节点的时候，大量的数据需要移动。比如在这里增加一个节点 N3，因此 hash 方式变为了 mod 4。

**均衡问题**：原始数据的特征值分布不均匀，导致大量的数据集中到一个物理节点上；第二，对于可修改的记录数据，单条记录的数据变大。

高级玩法是抽象 *slot*，基于 *Hash* 的 *Slot Sharding*，例如 *Redis-Cluster*。

![image](https://github.com/lecc2cc/microgo/blob/master/images/08-14-2021-06-10-23.png?raw=true)

redis-cluster 把16384 槽按照节点数量进行平均分配，由节点进行管理。

对每个 key 按照 CRC16 规则进行 hash 运算，把 hash 结果对16383进行取余，把余数发送给 Redis 节点。

需要注意的是：Redis Cluster 的节点之间会共享消息，每个节点都会知道是哪个节点负责哪个范围内的数据槽。

假设需要新增node-6时，需要之前每个节点划分一些slot给node-6，同时将对于划分出去slot的key迁移到node-6节点，从而避免所有的node遍历所有key后才迁移到新节点。

![image](https://github.com/lecc2cc/microgo/blob/master/images/08-15-2021-06-10-23.png?raw=true)

### 缓存模式

#### 1 数据一致性

Storage和Cache同步更新容易出现数据不一致。

在保证数据最终一致性的情况下，模拟MySQL Slave做数据复制，再把消息投递到Kafka，保证至少一次消费：

+ 同步操作DB

+ 同步操作Cache

+ 利用Job消费消息（订阅MySQL的binlong日志），重新补偿一次缓存操作

  

Cache Aside模型中，读缓存Miss的回填操作，和修改数据同步更新缓存，包括消息队列的异步补偿缓存，都无法满足“Happens Before”，会存在相互覆盖的情况。

![image](https://github.com/lecc2cc/microgo/blob/master/images/08-18-2021-06-10-23.png?raw=true)

例如，在左边select到v1数据后，然后右边完成update的v2数据并删除缓存，而此次左边的set操作将保持的是v1数据，导致不一致问题。



